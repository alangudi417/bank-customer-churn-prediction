{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d0a110",
   "metadata": {},
   "source": [
    "# Beta Bank\n",
    "Customers of Beta Bank are leaving little by little every month. Bankers have discovered that it is cheaper to retain existing customers than to attract new ones. <br>\n",
    "We need to predict whether a customer will leave the bank soon. You have data on customers’ past behavior and contract terminations with the bank. <br>\n",
    "Create a model with the highest possible F1 score. To pass the review, you need an F1 score of at least 0.59. Check the F1 score on the test set. In addition, you must measure the AUC-ROC metric and compare it with the F1 score.\n",
    "\n",
    "# Data Description\n",
    "You can find the data in the file /datasets/Churn.csv.\n",
    "\n",
    "Features\n",
    "\n",
    "- RowNumber: data row index\n",
    "- CustomerId: unique customer identifier\n",
    "- Surname: last name\n",
    "- CreditScore: credit score\n",
    "- Geography: country of residence\n",
    "- Gender: gender\n",
    "- Age: age\n",
    "- Tenure: period during which the customer’s fixed-term deposit has matured (years)\n",
    "- Balance: account balance\n",
    "- NumOfProducts: number of banking products used by the customer\n",
    "- HasCrCard: whether the customer has a credit card (1 – yes; 0 – no)\n",
    "- IsActiveMember: customer activity status (1 – yes; 0 – no)\n",
    "- EstimatedSalary: estimated salary\n",
    "\n",
    "Target\n",
    "- Exited: the customer has left the bank (1 – yes; 0 – no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b329e217",
   "metadata": {},
   "source": [
    "# 1. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600991aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592469ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Import classification libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
    "\n",
    "from src.null_columns import show_null_columns\n",
    "from src.column_names import stardard_col_names\n",
    "from src.modeling import train_evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the info from the Datasets\n",
    "df_churn = pd.read_csv('../data/raw/churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bb7df8",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing\n",
    "### 2.1 Copy original Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce48e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone datasets to keep the original with no changes\n",
    "df_churn_clean = df_churn.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b707e14",
   "metadata": {},
   "source": [
    "### 2.2 Review duplicate / null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3056f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General View\n",
    "df_churn.info()\n",
    "print()\n",
    "print(df_churn.sample(3))\n",
    "\n",
    "\"\"\"\n",
    "Findings:\n",
    "Reviewing the column headers, we have to standardize to snake_case\n",
    "\"\"\"\n",
    "stardard_col_names(df_churn_clean)\n",
    "df_churn_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ad42a",
   "metadata": {},
   "source": [
    "Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa16ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the duplicate rows are:\", df_churn_clean.duplicated().sum())  # Sum of Duplicated rows\n",
    "print('number of duplicate values in column \"customer_id\":', df_churn_clean['customer_id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49799f8f",
   "metadata": {},
   "source": [
    "Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49258ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_null_columns(df_churn_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d83286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Findings:\n",
    "As the results of null values in column 'tenure' is 9.09%, we have to evaluate how the data is distributed to decide how to impute the data.\n",
    "\"\"\"\n",
    "# Visualize distribution\n",
    "df_churn_clean['tenure'].hist(bins=30)\n",
    "plt.title('Distribution of Column')\n",
    "plt.show()\n",
    "\n",
    "# Check statistics\n",
    "print(df_churn_clean['tenure'].describe().round(2))\n",
    "print(f\"Skewness: {df_churn_clean['tenure'].skew()}\")\n",
    "\n",
    "\"\"\"\n",
    "Findings:\n",
    "The data in column \"tenure\" result very simetric (skewness = 0.016), the imputation can be either mean or median,\n",
    "in this case, considering tenure (years / months), I'll take median to keep the values (int).\n",
    "\"\"\"\n",
    "df_churn_clean['tenure'] = df_churn_clean['tenure'].fillna(df_churn_clean['tenure'].median())\n",
    "\n",
    "# Change dtypes to keep the integrity and optimization of the data\n",
    "df_churn_clean['tenure'] = df_churn_clean['tenure'].astype(int)\n",
    "df_churn_clean['geography'] = df_churn_clean['geography'].astype('category')\n",
    "df_churn_clean['gender'] = df_churn_clean['gender'].astype('category')\n",
    "df_churn_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5908a8fb",
   "metadata": {},
   "source": [
    "### 2.3 Preparing data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Findings:\n",
    "To proceed with a ML model, some columns with 'non-useful' variables will be removed, and change 2 categorical columns to numerical\n",
    "using the one-hot coding. With this, the data will be ready for modeling.\n",
    "\"\"\"\n",
    "df_churn_clean = df_churn_clean.drop(['row_number', 'customer_id', 'surname'], axis=1)   # Removing columns\n",
    "df_churn_clean = pd.get_dummies(df_churn_clean, columns=['geography', 'gender'], drop_first=True)   # transforming data using one-hot coding\n",
    "df_churn_clean.columns = df_churn_clean.columns.str.lower()\n",
    "print(df_churn_clean.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d034f",
   "metadata": {},
   "source": [
    "# 3. Modeling\n",
    "### 3.1 Data Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target\n",
    "features = df_churn_clean.drop(['exited'], axis=1)\n",
    "target = df_churn_clean['exited']\n",
    "\n",
    "# Divide the data (train and test) by using train-test split\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa23d8c",
   "metadata": {},
   "source": [
    "### 3.2 Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Findings:\n",
    "Here we need to see if how balanced is the data in the target column 'exited'. \n",
    "This is to ensure the target distribution was not heavily skewed, since class imbalance can bias model training and make accuracy misleading.\n",
    "\"\"\"\n",
    "# Class balance\n",
    "print(df_churn_clean['exited'].value_counts())\n",
    "print()\n",
    "print(df_churn_clean['exited'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Class Balance Visualization\n",
    "df_churn_clean['exited'].value_counts().plot(kind='bar')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Exited (0 = No, 1 = Yes)')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8345de0e",
   "metadata": {},
   "source": [
    "Findings: <br>\n",
    "With the class balance analysis, it can be observed that there is no balance between the classes [0, 1]. <br>\n",
    "The results show that 79.63% of customers have not left the bank, while 20.37% of customers have left. <br>\n",
    "Metrics to use: F1-score and ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20afad47",
   "metadata": {},
   "source": [
    "### 3.3 Training\n",
    "For the selection of models to be trained, given the characteristics and interpretation of the dataset, the problem is a classification task. <br>\n",
    "Here, I'll select 3 of classification models to determine which one gives the best and more accurate result, and each model will be compared with class_balance=True, and class_balance=False. This, because the imbalance is ~80/20.\n",
    "#### 3.3.1 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a61a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "results_dtc = []\n",
    "\n",
    "dtc_params = {\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 20,\n",
    "    \"random_state\": 12345\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b15534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Without class_balance\n",
    "model_dtc, f1_dtc, auc_dtc = train_evaluate_model(\n",
    "    DecisionTreeClassifier,\n",
    "    dtc_params,\n",
    "    features_train,\n",
    "    target_train, \n",
    "    features_test, \n",
    "    target_test,\n",
    "    use_class_weight=False\n",
    ")\n",
    "\n",
    "results_dtc.append({\n",
    "    \"model\": \"DecisionTree\",\n",
    "    \"class_weight\": \"None\",\n",
    "    \"f1\": f1_dtc,\n",
    "    \"auc\": auc_dtc\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09839c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model With class_balance\n",
    "model_dtc_bal, f1_dtc_bal, auc_dtc_bal = train_evaluate_model(\n",
    "    DecisionTreeClassifier,\n",
    "    dtc_params,\n",
    "    features_train,\n",
    "    target_train, \n",
    "    features_test, \n",
    "    target_test,\n",
    "    use_class_weight=True\n",
    ")\n",
    "\n",
    "results_dtc.append({\n",
    "    \"model\": \"DecisionTree\",\n",
    "    \"class_weight\": \"Balanced\",\n",
    "    \"f1\": f1_dtc_bal,\n",
    "    \"auc\": auc_dtc_bal\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of Models\n",
    "results_dtc = pd.DataFrame(results_dtc)\n",
    "results_dtc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf3844",
   "metadata": {},
   "source": [
    "#### 3.3.2 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "results_lr = []\n",
    "\n",
    "lr_params = {\n",
    "    \"solver\":'liblinear',\n",
    "    \"random_state\": 12345\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653298c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Without class_balance\n",
    "model_lr, f1_lr, auc_lr = train_evaluate_model(\n",
    "    LogisticRegression,\n",
    "    lr_params,\n",
    "    features_train,\n",
    "    target_train, \n",
    "    features_test, \n",
    "    target_test,\n",
    "    use_class_weight=False\n",
    ")\n",
    "\n",
    "results_lr.append({\n",
    "    \"model\": \"LogisticRegression\",\n",
    "    \"class_weight\": \"None\",\n",
    "    \"f1\": f1_lr,\n",
    "    \"auc\": auc_lr\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45917bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model With class_balance\n",
    "model_lr_bal, f1_lr_bal, auc_lr_bal = train_evaluate_model(\n",
    "    LogisticRegression,\n",
    "    lr_params,\n",
    "    features_train,\n",
    "    target_train, \n",
    "    features_test, \n",
    "    target_test,\n",
    "    use_class_weight=True\n",
    ")\n",
    "\n",
    "results_lr.append({\n",
    "    \"model\": \"LogisticRegression\",\n",
    "    \"class_weight\": \"Balanced\",\n",
    "    \"f1\": f1_lr_bal,\n",
    "    \"auc\": auc_lr_bal\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of Models\n",
    "results_lr = pd.DataFrame(results_lr)\n",
    "results_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606baa5",
   "metadata": {},
   "source": [
    "#### 3.3 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d68000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "results_rfc = []\n",
    "\n",
    "rfc_params = {\n",
    "    \"n_estimators\": 20,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"random_state\":12345\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b924ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Without class_balance\n",
    "model_rfc, f1_rfc, auc_rfc = train_evaluate_model(\n",
    "    RandomForestClassifier,\n",
    "    rfc_params,\n",
    "    features_train,\n",
    "    target_train, \n",
    "    features_test, \n",
    "    target_test,\n",
    "    use_class_weight=False\n",
    ")\n",
    "\n",
    "results_rfc.append({\n",
    "    \"model\": \"RandomForest\",\n",
    "    \"class_weight\": \"None\",\n",
    "    \"f1\": f1_rfc,\n",
    "    \"auc\": auc_rfc\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model With class_balance\n",
    "model_rfc_bal, f1_rfc_bal, auc_rfc_bal = train_evaluate_model(\n",
    "    RandomForestClassifier,\n",
    "    rfc_params,\n",
    "    features_train,\n",
    "    target_train, \n",
    "    features_test, \n",
    "    target_test,\n",
    "    use_class_weight=True\n",
    ")\n",
    "\n",
    "results_rfc.append({\n",
    "    \"model\": \"RandomForest\",\n",
    "    \"class_weight\": \"Balanced\",\n",
    "    \"f1\": f1_rfc_bal,\n",
    "    \"auc\": auc_rfc_bal\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fafd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of Models\n",
    "results_rfc = pd.DataFrame(results_rfc)\n",
    "results_rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da569d7e",
   "metadata": {},
   "source": [
    "After running three different classification models, the one that achieved the most optimal F1 score was the RandomForestClassifier, using the undersampling balancing technique.\n",
    "Below are the results obtained:\n",
    "\n",
    "DecisionTreeClassifier\n",
    "-\tUnbalanced: F1 = 0.5736, AUC = 0.7161\n",
    "-\tWith class_weight: F1 = 0.5651, AUC = 0.7469\n",
    "\n",
    "LogisticRegression\n",
    "-\tUnbalanced: F1 = 0.1171, AUC = 0.5224\n",
    "-\tWith class_weight: F1 = 0.4893, AUC = 0.6923\n",
    "\n",
    "RandomForestClassifier\n",
    "-\tUnbalanced: F1 = 0.5632, AUC = 0.7035\n",
    "-\tWith class_weight: F1 = 0.6363, AUC = 0.7611"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402e29a",
   "metadata": {},
   "source": [
    "# 4. Conclusion\n",
    "As a conclusion, the objective of this project was to develop a machine learning model to predict customer churn for Beta Bank, targeting an F1 score of at least 0.59.\n",
    "In the project, to select the right model to fit the desired score, 2 important topics were considered:\n",
    "\n",
    "1. Model Evaluation:\n",
    "We tested three classification algorithms (Decision Tree, Logistic Regression, and Random Forest) and compared their performance using both unbalanced data and class balancing techniques (Class Weighting). <br>\n",
    "- Decision Tree: Struggled to meet the threshold, with F1 scores hovering around 0.56-0.57 regardless of balancing.\n",
    "- Logistic Regression: Performed poorly due to the non-linear nature of the data, achieving a maximum F1 score of only ~0.49 even with balancing.\n",
    "- Random Forest: Demonstrated the best performance. While the unbalanced model fell short (F1 ~0.56), applying Class Weighting significantly boosted its predictive power.\n",
    "\n",
    "2. Final Model Selection:\n",
    "- The Random Forest Classifier with class_weight='balanced' is the final selected model.\n",
    "- Final F1 Score: 0.6363 (Successfully exceeds the 0.59 target).\n",
    "- AUC-ROC Score: 0.7611 (Indicates the model has a good capability to distinguish between retaining and exiting customers).\n",
    "\n",
    "Business Impact:\n",
    "This model effectively balances Precision and Recall, making it a valuable tool for Beta Bank. It allows the bank to proactively target at-risk customers with retention strategies, thereby reducing churn and saving costs associated with acquiring new customers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
